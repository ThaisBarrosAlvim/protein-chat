{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def process_pdfs(chunk, folder_path):\n",
    "    pdf_docs = []\n",
    "    print(f'processing chunk: of len:{len(chunk)}')\n",
    "    for file_name in chunk:\n",
    "        if file_name.endswith('.pdf'):\n",
    "            try:\n",
    "                # TODO usar tesseract para extrair texto de pdfs imagem.\n",
    "                loader = PDFPlumberLoader(os.path.join(folder_path, file_name))\n",
    "                docs = loader.load()\n",
    "                if len(docs) == 0:\n",
    "                    print(f'warning: doc: {file_name} is empty')\n",
    "                pdf_docs.extend(docs)\n",
    "            except Exception as e:\n",
    "                print(f'erro: {e} ao processar pdf {file_name}')\n",
    "    return pdf_docs\n",
    "\n",
    "\n",
    "def save_docs_to_jsonl(array, file_path: str) -> None:\n",
    "    with open(file_path, 'w') as jsonl_file:\n",
    "        for doc in array:\n",
    "            jsonl_file.write(doc.json() + '\\n')\n",
    "\n",
    "\n",
    "def ensure_utf8(text):\n",
    "    return text.encode('utf-8', errors='replace').decode('utf-8')\n",
    "\n",
    "\n",
    "def load_docs_from_jsonl(file_path):\n",
    "    array = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "        lines = jsonl_file.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # Converte a linha para UTF-8, garantindo que todos os caracteres sejam válidos\n",
    "        utf8_line = ensure_utf8(line)\n",
    "        data = json.loads(utf8_line)\n",
    "        results = Document(**data)\n",
    "        array.append(results)\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "# Carregar os documentos e aplicar a conversão\n",
    "docs = load_docs_from_jsonl('data_finish.jsonl')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)"
   ],
   "id": "234ed989b618c909",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import weaviate\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\", )\n",
    "db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client, index_name='protein_articles')\n"
   ],
   "id": "8cb6129a8da087fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "weaviate_client.collections.create(\n",
    "    \"ProteinCollection\",\n",
    "    vectorizer_config=Configure.Vectorizer.text2vec_ollama(\n",
    "        api_endpoint=\"http://ollama:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "        model=\"mxbai-embed-large\",  # The model to use, e.g. \"nomic-embed-text\"\n",
    "    ),\n",
    "    properties=[  # properties configuration is optional\n",
    "        Property(name=\"title\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"body\", data_type=DataType.TEXT),\n",
    "        Property(name=\"page\", data_type=DataType.INT, skip_vectorization=True),\n",
    "        Property(name=\"doi\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"pk\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"proteins_structures\", data_type=DataType.TEXT_ARRAY),\n",
    "    ]\n",
    ")\n",
    "weaviate_client.close()"
   ],
   "id": "6a052b41d4824cd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weaviate_client = weaviate.connect_to_local()\n",
    "collection = weaviate_client.collections.get(\"ProteinCollection\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for src_obj in split_docs:\n",
    "        try:\n",
    "            weaviate_obj = {\n",
    "                \"pk\": src_obj.metadata.get(\"id\", ''),\n",
    "                \"doi\": src_obj.metadata.get(\"doi\", ''),\n",
    "                \"page\": src_obj.metadata.get(\"page\", ''),\n",
    "                \"title\": src_obj.metadata.get(\"title\", ''),\n",
    "                \"body\": src_obj.page_content,\n",
    "                \"proteins_structures\": src_obj.metadata.get(\"proteins_structures\", []),\n",
    "            }\n",
    "\n",
    "            batch.add_object(\n",
    "                properties=weaviate_obj,\n",
    "            )\n",
    "        except Exception as err:\n",
    "            print(f'Error: {err}, on id {src_obj.metadata.get(\"id\", \"\")}')\n",
    "weaviate_client.close()"
   ],
   "id": "a57f18625413b778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from weaviate.collections.classes.grpc import MetadataQuery\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "collection = weaviate_client.collections.get(\"ProteinCollection\")\n",
    "\n",
    "response = collection.query.hybrid(\n",
    "    query=\"what is mobile loop ?\",\n",
    "    return_metadata=MetadataQuery(score=True, explain_score=True, distance=True, is_consistent=True),\n",
    "    limit=3,\n",
    "    # include_vector=True,\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties['body'][:100], '...')\n",
    "    print(\n",
    "        f'score: {o.metadata.score}, explain: {o.metadata.explain_score}, distance: {o.metadata.distance}, is_consistent: {o.metadata.is_consistent}')\n",
    "    # print(o.vector[\"default\"])\n",
    "weaviate_client.close()"
   ],
   "id": "b0a8196b796371ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weaviate_client = weaviate.connect_to_local()\n",
    "collection = weaviate_client.collections.get(\"ProteinCollection\")\n",
    "\n",
    "count = 0\n",
    "for item in collection.iterator():\n",
    "    print(item.uuid, item.properties)\n",
    "    count += 1\n",
    "    if count > 3:\n",
    "        break\n",
    "weaviate_client.close()"
   ],
   "id": "b1dce87803e251b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T14:42:00.742065Z",
     "start_time": "2024-10-03T14:41:59.577710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "db = WeaviateVectorStore(client=weaviate_client, index_name='ProteinCollection',\n",
    "                         embedding=OllamaEmbeddings(model=\"mxbai-embed-large\", ), text_key='body')\n",
    "response = db.similarity_search(\"what is mobile loop ?\", alpha=0.5, k=20)\n",
    "weaviate_client.close()\n",
    "len(response)"
   ],
   "id": "8fe3a2b4ffeca4f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_166673/3749480761.py:4: ResourceWarning: unclosed <socket.socket fd=83, family=2, type=1, proto=6, laddr=('127.0.0.1', 56954), raddr=('127.0.0.1', 11434)>\n",
      "  db = WeaviateVectorStore(client=weaviate_client, index_name='ProteinCollection',\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# weaviate_client.connect()\n",
    "# weaviate_client.collections.delete_all()\n",
    "# weaviate_client.close()"
   ],
   "id": "1c92a632607f0fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weaviate_client.connect()\n",
    "try:\n",
    "    collections = weaviate_client.collections.list_all()\n",
    "finally:\n",
    "    weaviate_client.close()\n",
    "collections"
   ],
   "id": "b32711622e8cc925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T14:46:18.959212Z",
     "start_time": "2024-10-03T14:46:18.277289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weaviate_client = weaviate.connect_to_local()\n",
    "db = WeaviateVectorStore(client=weaviate_client, index_name='ProteinCollection',\n",
    "                         embedding=OllamaEmbeddings(model=\"mxbai-embed-large\"),\n",
    "                         text_key='body')\n",
    "retriever = db.as_retriever(search_kwargs={'k': 20})\n",
    "\n",
    "len(retriever.invoke('what is a mobile loop?'))\n"
   ],
   "id": "72ab04d846158b9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_166673/2645895327.py:2: ResourceWarning: unclosed <socket.socket fd=83, family=2, type=1, proto=6, laddr=('127.0.0.1', 48924), raddr=('127.0.0.1', 11434)>\n",
      "  db = WeaviateVectorStore(client=weaviate_client, index_name='ProteinCollection',\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/tmp/ipykernel_166673/2645895327.py:5: ResourceWarning: unclosed <socket.socket fd=80, family=2, type=1, proto=6, laddr=('127.0.0.1', 49608), raddr=('127.0.0.1', 11434)>\n",
      "  retriever = db.as_retriever(search_kwargs = {'k': 20})\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/mnt/TCC/protein-chat-flask/.venv/lib/python3.11/site-packages/weaviate/warnings.py:305: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T14:49:34.919210Z",
     "start_time": "2024-10-03T14:49:00.483994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "prompt = \"\"\"\n",
    "    1. Use the following pieces of context to answer the question at the end.\n",
    "            2. If you don't know the answer, just say \"I don't know\" but don't make up an answer on your own.\n",
    "            3. Keep the answer crisp and limited to 3-4 sentences.\n",
    "            \n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            After the answer, always say the source and page.\n",
    "            Helpful Answer:\n",
    "    \"\"\"\n",
    "llm = Ollama(model=\"llama3\")\n",
    "qa_chain_prompt = PromptTemplate.from_template(prompt)\n",
    "rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | qa_chain_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke('what is a mobile loop?')"
   ],
   "id": "a78e04235f170a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, a mobile loop refers to switch loop I (blue and magenta) in the structure of human Pim-1 kinase. This mobile loop can adopt different conformations depending on the binding of nucleotides or other molecules.\\n\\nSource: Science Magazine, Page 1236086'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
